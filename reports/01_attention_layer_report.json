{
  "timestamp": "2025-12-07 14:46:03",
  "model_config": {
    "dim": 768,
    "n_heads": 12,
    "n_kv_heads": 3,
    "compression_factor": 4,
    "use_convs": true,
    "use_qk_mean": true,
    "use_qk_norm": true,
    "use_rope": true
  },
  "speed_results": [
    {
      "forward_time_ms": 0.9620000026188791,
      "backward_time_ms": 7.159749997663312,
      "total_time_ms": 8.12175000028219,
      "throughput_samples_per_sec": 123.12617354206358,
      "batch_size": 1,
      "seq_len": 256,
      "flops": 239812608,
      "flops_per_sec": 29527208790.182865
    },
    {
      "forward_time_ms": 1.019940001424402,
      "backward_time_ms": 2.06210000324063,
      "total_time_ms": 3.082040004665032,
      "throughput_samples_per_sec": 324.46042182657646,
      "batch_size": 1,
      "seq_len": 512,
      "flops": 580288512,
      "flops_per_sec": 188280655384.63638
    },
    {
      "forward_time_ms": 1.1004600004525855,
      "backward_time_ms": 2.3783500015269965,
      "total_time_ms": 3.478810001979582,
      "throughput_samples_per_sec": 287.45461793859397,
      "batch_size": 1,
      "seq_len": 1024,
      "flops": 1563230208,
      "flops_per_sec": 449357742190.70874
    },
    {
      "forward_time_ms": 0.9795700054382905,
      "backward_time_ms": 2.348789997631684,
      "total_time_ms": 3.3283600030699745,
      "throughput_samples_per_sec": 1201.793074159804,
      "batch_size": 4,
      "seq_len": 256,
      "flops": 959250432,
      "flops_per_sec": 288205131390.60004
    },
    {
      "forward_time_ms": 1.0197499941568822,
      "backward_time_ms": 2.013059999444522,
      "total_time_ms": 3.032809993601404,
      "throughput_samples_per_sec": 1318.9088694772058,
      "batch_size": 4,
      "seq_len": 512,
      "flops": 2321154048,
      "flops_per_sec": 765347665332.53
    },
    {
      "forward_time_ms": 1.2380100059090182,
      "backward_time_ms": 2.609389997087419,
      "total_time_ms": 3.8474000029964373,
      "throughput_samples_per_sec": 1039.6631483299668,
      "batch_size": 4,
      "seq_len": 1024,
      "flops": 6252920832,
      "flops_per_sec": 1625232839613.789
    },
    {
      "forward_time_ms": 0.9855299984337762,
      "backward_time_ms": 2.054570001200773,
      "total_time_ms": 3.040099999634549,
      "throughput_samples_per_sec": 2631.492385435243,
      "batch_size": 8,
      "seq_len": 256,
      "flops": 1918500864,
      "flops_per_sec": 631065051883.3668
    },
    {
      "forward_time_ms": 1.1046200030250475,
      "backward_time_ms": 2.339330001268536,
      "total_time_ms": 3.4439500042935833,
      "throughput_samples_per_sec": 2322.914092837113,
      "batch_size": 8,
      "seq_len": 512,
      "flops": 4642308096,
      "flops_per_sec": 1347960362436.278
    },
    {
      "forward_time_ms": 1.4360100001795217,
      "backward_time_ms": 3.3541500044520944,
      "total_time_ms": 4.790160004631616,
      "throughput_samples_per_sec": 1670.090350273223,
      "batch_size": 8,
      "seq_len": 1024,
      "flops": 12505841664,
      "flops_per_sec": 2610735685636.4033
    }
  ],
  "memory_results": [
    {
      "peak_memory_mb": 23.39306640625,
      "activation_memory_mb": 21.494625091552734,
      "parameter_memory_mb": 1.8984413146972656,
      "allocated_memory_mb": 21.67333984375,
      "reserved_memory_mb": 28.0,
      "batch_size": 1,
      "seq_len": 256,
      "memory_per_sample_mb": 23.39306640625
    },
    {
      "peak_memory_mb": 30.03271484375,
      "activation_memory_mb": 28.134273529052734,
      "parameter_memory_mb": 1.8984413146972656,
      "allocated_memory_mb": 23.92333984375,
      "reserved_memory_mb": 50.0,
      "batch_size": 1,
      "seq_len": 512,
      "memory_per_sample_mb": 30.03271484375
    },
    {
      "peak_memory_mb": 39.13671875,
      "activation_memory_mb": 37.238277435302734,
      "parameter_memory_mb": 1.8984413146972656,
      "allocated_memory_mb": 26.17333984375,
      "reserved_memory_mb": 58.0,
      "batch_size": 1,
      "seq_len": 1024,
      "memory_per_sample_mb": 39.13671875
    },
    {
      "peak_memory_mb": 39.14501953125,
      "activation_memory_mb": 37.246578216552734,
      "parameter_memory_mb": 1.8984413146972656,
      "allocated_memory_mb": 26.92333984375,
      "reserved_memory_mb": 58.0,
      "batch_size": 4,
      "seq_len": 256,
      "memory_per_sample_mb": 9.7862548828125
    },
    {
      "peak_memory_mb": 57.85302734375,
      "activation_memory_mb": 55.954586029052734,
      "parameter_memory_mb": 1.8984413146972656,
      "allocated_memory_mb": 32.17333984375,
      "reserved_memory_mb": 72.0,
      "batch_size": 4,
      "seq_len": 512,
      "memory_per_sample_mb": 14.4632568359375
    },
    {
      "peak_memory_mb": 94.28076171875,
      "activation_memory_mb": 92.38232040405273,
      "parameter_memory_mb": 1.8984413146972656,
      "allocated_memory_mb": 44.17333984375,
      "reserved_memory_mb": 122.0,
      "batch_size": 4,
      "seq_len": 1024,
      "memory_per_sample_mb": 23.5701904296875
    },
    {
      "peak_memory_mb": 60.44189453125,
      "activation_memory_mb": 58.543453216552734,
      "parameter_memory_mb": 1.8984413146972656,
      "allocated_memory_mb": 32.17333984375,
      "reserved_memory_mb": 72.0,
      "batch_size": 8,
      "seq_len": 256,
      "memory_per_sample_mb": 7.55523681640625
    },
    {
      "peak_memory_mb": 94.2939453125,
      "activation_memory_mb": 92.39550399780273,
      "parameter_memory_mb": 1.8984413146972656,
      "allocated_memory_mb": 44.17333984375,
      "reserved_memory_mb": 126.0,
      "batch_size": 8,
      "seq_len": 512,
      "memory_per_sample_mb": 11.7867431640625
    },
    {
      "peak_memory_mb": 166.8876953125,
      "activation_memory_mb": 164.98925399780273,
      "parameter_memory_mb": 1.8984413146972656,
      "allocated_memory_mb": 68.17333984375,
      "reserved_memory_mb": 216.0,
      "batch_size": 8,
      "seq_len": 1024,
      "memory_per_sample_mb": 20.8609619140625
    }
  ],
  "gradient_analysis": {
    "mean_grad_norm": 19777.172658538817,
    "max_grad_norm": 66760.9375,
    "min_grad_norm": 113.3976058959961,
    "grad_norm_q": 7603.0048828125,
    "grad_norm_k": 9664.96484375,
    "grad_norm_v": 66760.9375,
    "grad_norm_o": 40480.65625,
    "vanishing_gradient_detected": false,
    "exploding_gradient_detected": true
  },
  "learning_results": {
    "initial_loss": 1.0030075311660767,
    "final_loss": 0.9981406927108765,
    "loss_improvement": 0.004852245128229152,
    "convergence_steps": 1,
    "gradient_flow_score": 3.107354280890323,
    "learning_capacity_score": 49.98522451282292
  },
  "component_analysis": {
    "compression_effectiveness": {
      "compression_factor": 4,
      "param_reduction_ratio": 0.75,
      "latent_dim": 192,
      "original_dim": 768,
      "convolutions_enabled": true
    },
    "qk_mean_impact": {
      "enabled": true,
      "n_groups": 4
    },
    "head_reshaping_efficiency": {
      "n_heads": 12,
      "n_kv_heads": 3,
      "gqa_ratio": 4.0,
      "head_dim": 16,
      "kv_cache_reduction": 0.25
    },
    "normalization_stats": {
      "qk_norm_enabled": true,
      "key_temperature": 0.93192458152771
    }
  },
  "optimization_recommendations": [
    "\u26a0\ufe0f  Backward pass is much slower than forward. Consider:\n   - Enabling gradient checkpointing in full model\n   - Using 16-bit precision (float16/bfloat16)\n   - Reducing attention computation with lower compression",
    "\u26a0\ufe0f  Exploding gradients detected. Fix with:\n   - Reduce learning rate\n   - Enable gradient clipping\n   - Use layer normalization before attention\n   - Decrease compression factor (too aggressive compression)",
    "\u26a0\ufe0f  Low learning capacity score. Suggestions:\n   - Reduce compression factor for better expressivity\n   - Increase number of attention heads\n   - Try different kernel sizes for convolutions\n   - Verify data preprocessing is correct"
  ]
}